# Comparing `tmp/tianmoucv-0.2.2.2-py3-none-any.whl.zip` & `tmp/tianmoucv-0.3.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,30 +1,42 @@
-Zip file size: 6594494 bytes, number of entries: 28
--rw-r--r--  2.0 unx      224 b- defN 24-Apr-11 18:07 tianmoucv/CONSTANT.py
--rw-r--r--  2.0 unx      308 b- defN 24-Apr-11 18:07 tianmoucv/__init__.py
--rw-r--r--  2.0 unx    14588 b- defN 24-Apr-11 18:07 tianmoucv/algorithm.py
--rw-r--r--  2.0 unx     4172 b- defN 24-Apr-11 18:07 tianmoucv/controller.py
--rw-r--r--  2.0 unx    24556 b- defN 24-Apr-11 18:07 tianmoucv/isp.py
--rw-r--r--  2.0 unx       44 b- defN 24-Apr-11 18:07 tianmoucv/data/__init__.py
--rw-r--r--  2.0 unx     9916 b- defN 24-Apr-11 18:07 tianmoucv/data/tianmoucData.py
--rw-r--r--  2.0 unx    25496 b- defN 24-Apr-11 18:07 tianmoucv/data/tianmoucData_basic.py
--rw-r--r--  2.0 unx       51 b- defN 24-Apr-11 18:07 tianmoucv/features/__init__.py
--rw-r--r--  2.0 unx    15371 b- defN 24-Apr-11 18:07 tianmoucv/features/diff.py
--rw-r--r--  2.0 unx      150 b- defN 24-Apr-11 18:07 tianmoucv/rdp_usb/CMakeLists.txt
--rw-r--r--  2.0 unx      283 b- defN 24-Apr-11 18:07 tianmoucv/rdp_usb/ReadMe.md
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-11 18:07 tianmoucv/rdp_usb/__init__.py
--rw-r--r--  2.0 unx      818 b- defN 24-Apr-11 18:07 tianmoucv/rdp_usb/compile_pybind.bat
--rwxr-xr-x  2.0 unx      165 b- defN 24-Apr-11 18:07 tianmoucv/rdp_usb/compile_pybind.sh
--rw-r--r--  2.0 unx    72985 b- defN 24-Apr-11 18:07 tianmoucv/rdp_usb/rod_decoder_py.cpp
--rw-r--r--  2.0 unx      677 b- defN 24-Apr-11 18:07 tianmoucv/rdp_usb/try_pcie2usb_conv.py
--rw-r--r--  2.0 unx     2505 b- defN 24-Apr-11 18:07 tianmoucv/rdp_usb/try_usb_data.py
--rw-r--r--  2.0 unx      322 b- defN 24-Apr-11 18:07 tianmoucv/reconstructor/__init__.py
--rw-r--r--  2.0 unx     6786 b- defN 24-Apr-11 18:07 tianmoucv/reconstructor/integration.py
--rw-r--r--  2.0 unx     6197 b- defN 24-Apr-11 18:07 tianmoucv/reconstructor/modules.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-11 18:07 tianmoucv/reconstructor/weight/__init__.py
--rw-r--r--  2.0 unx  7048899 b- defN 24-Apr-11 18:07 tianmoucv/reconstructor/weight/direct_0109_with_HDR_GTver_best.ckpt
--rw-r--r--  2.0 unx    35149 b- defN 24-Apr-11 18:24 tianmoucv-0.2.2.2.dist-info/LICENSE
--rw-r--r--  2.0 unx     1953 b- defN 24-Apr-11 18:24 tianmoucv-0.2.2.2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-11 18:24 tianmoucv-0.2.2.2.dist-info/WHEEL
--rw-r--r--  2.0 unx       10 b- defN 24-Apr-11 18:24 tianmoucv-0.2.2.2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2441 b- defN 24-Apr-11 18:24 tianmoucv-0.2.2.2.dist-info/RECORD
-28 files, 7274158 bytes uncompressed, 6590520 bytes compressed:  9.4%
+Zip file size: 71594 bytes, number of entries: 40
+-rw-r--r--  2.0 unx      341 b- defN 24-Apr-20 13:32 tianmoucv/__init__.py
+-rw-r--r--  2.0 unx      994 b- defN 24-Apr-20 13:32 tianmoucv/tools.py
+-rw-r--r--  2.0 unx       44 b- defN 24-Apr-20 13:32 tianmoucv/data/__init__.py
+-rw-r--r--  2.0 unx    12544 b- defN 24-Apr-20 13:32 tianmoucv/data/tianmoucData.py
+-rw-r--r--  2.0 unx    25536 b- defN 24-Apr-20 13:32 tianmoucv/data/tianmoucData_basic.py
+-rw-r--r--  2.0 unx       49 b- defN 24-Apr-20 13:32 tianmoucv/isp/__init__.py
+-rw-r--r--  2.0 unx    15720 b- defN 24-Apr-20 13:32 tianmoucv/isp/isp_basic.py
+-rw-r--r--  2.0 unx     5423 b- defN 24-Apr-20 13:32 tianmoucv/isp/transform.py
+-rw-r--r--  2.0 unx       62 b- defN 24-Apr-20 13:32 tianmoucv/nn/__init__.py
+-rw-r--r--  2.0 unx       44 b- defN 24-Apr-20 13:32 tianmoucv/nn/unet_modules.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-20 13:32 tianmoucv/proc/__init__.py
+-rw-r--r--  2.0 unx       51 b- defN 24-Apr-20 13:32 tianmoucv/proc/features/__init__.py
+-rw-r--r--  2.0 unx    12331 b- defN 24-Apr-20 13:32 tianmoucv/proc/features/diff.py
+-rw-r--r--  2.0 unx       48 b- defN 24-Apr-20 13:32 tianmoucv/proc/nn/__init__.py
+-rw-r--r--  2.0 unx     5473 b- defN 24-Apr-20 13:32 tianmoucv/proc/nn/spy_modules.py
+-rw-r--r--  2.0 unx     9559 b- defN 24-Apr-20 13:32 tianmoucv/proc/nn/unet_modules.py
+-rw-r--r--  2.0 unx     9995 b- defN 24-Apr-20 13:32 tianmoucv/proc/nn/utils.py
+-rw-r--r--  2.0 unx       67 b- defN 24-Apr-20 13:32 tianmoucv/proc/opticalflow/__init__.py
+-rw-r--r--  2.0 unx     9037 b- defN 24-Apr-20 13:32 tianmoucv/proc/opticalflow/basic.py
+-rw-r--r--  2.0 unx     8041 b- defN 24-Apr-20 13:32 tianmoucv/proc/opticalflow/estimator.py
+-rw-r--r--  2.0 unx     3178 b- defN 24-Apr-20 13:32 tianmoucv/proc/opticalflow/spy_net.py
+-rw-r--r--  2.0 unx      432 b- defN 24-Apr-20 13:32 tianmoucv/proc/reconstruct/__init__.py
+-rw-r--r--  2.0 unx     6943 b- defN 24-Apr-20 13:32 tianmoucv/proc/reconstruct/basic.py
+-rw-r--r--  2.0 unx     2495 b- defN 24-Apr-20 13:32 tianmoucv/proc/reconstruct/integration.py
+-rw-r--r--  2.0 unx     5099 b- defN 24-Apr-20 13:32 tianmoucv/proc/reconstruct/tiny_unet.py
+-rw-r--r--  2.0 unx       30 b- defN 24-Apr-20 13:32 tianmoucv/proc/tracking/__init__.py
+-rw-r--r--  2.0 unx     3078 b- defN 24-Apr-20 13:32 tianmoucv/proc/tracking/feature_tracker.py
+-rw-r--r--  2.0 unx      150 b- defN 24-Apr-20 13:32 tianmoucv/rdp_usb/CMakeLists.txt
+-rw-r--r--  2.0 unx      283 b- defN 24-Apr-20 13:32 tianmoucv/rdp_usb/ReadMe.md
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-20 13:32 tianmoucv/rdp_usb/__init__.py
+-rw-r--r--  2.0 unx      818 b- defN 24-Apr-20 13:32 tianmoucv/rdp_usb/compile_pybind.bat
+-rwxr-xr-x  2.0 unx      165 b- defN 24-Apr-20 13:32 tianmoucv/rdp_usb/compile_pybind.sh
+-rw-r--r--  2.0 unx    72985 b- defN 24-Apr-20 13:32 tianmoucv/rdp_usb/rod_decoder_py.cpp
+-rw-r--r--  2.0 unx      677 b- defN 24-Apr-20 13:32 tianmoucv/rdp_usb/try_pcie2usb_conv.py
+-rw-r--r--  2.0 unx     2505 b- defN 24-Apr-20 13:32 tianmoucv/rdp_usb/try_usb_data.py
+-rw-r--r--  2.0 unx    35149 b- defN 24-Apr-20 13:34 tianmoucv-0.3.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     2860 b- defN 24-Apr-20 13:34 tianmoucv-0.3.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-20 13:34 tianmoucv-0.3.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       10 b- defN 24-Apr-20 13:34 tianmoucv-0.3.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3484 b- defN 24-Apr-20 13:34 tianmoucv-0.3.0.dist-info/RECORD
+40 files, 255792 bytes uncompressed, 65960 bytes compressed:  74.2%
```

## zipnote {}

```diff
@@ -1,85 +1,121 @@
-Filename: tianmoucv/CONSTANT.py
+Filename: tianmoucv/__init__.py
 Comment: 
 
-Filename: tianmoucv/__init__.py
+Filename: tianmoucv/tools.py
 Comment: 
 
-Filename: tianmoucv/algorithm.py
+Filename: tianmoucv/data/__init__.py
 Comment: 
 
-Filename: tianmoucv/controller.py
+Filename: tianmoucv/data/tianmoucData.py
 Comment: 
 
-Filename: tianmoucv/isp.py
+Filename: tianmoucv/data/tianmoucData_basic.py
 Comment: 
 
-Filename: tianmoucv/data/__init__.py
+Filename: tianmoucv/isp/__init__.py
 Comment: 
 
-Filename: tianmoucv/data/tianmoucData.py
+Filename: tianmoucv/isp/isp_basic.py
 Comment: 
 
-Filename: tianmoucv/data/tianmoucData_basic.py
+Filename: tianmoucv/isp/transform.py
 Comment: 
 
-Filename: tianmoucv/features/__init__.py
+Filename: tianmoucv/nn/__init__.py
 Comment: 
 
-Filename: tianmoucv/features/diff.py
+Filename: tianmoucv/nn/unet_modules.py
 Comment: 
 
-Filename: tianmoucv/rdp_usb/CMakeLists.txt
+Filename: tianmoucv/proc/__init__.py
 Comment: 
 
-Filename: tianmoucv/rdp_usb/ReadMe.md
+Filename: tianmoucv/proc/features/__init__.py
 Comment: 
 
-Filename: tianmoucv/rdp_usb/__init__.py
+Filename: tianmoucv/proc/features/diff.py
 Comment: 
 
-Filename: tianmoucv/rdp_usb/compile_pybind.bat
+Filename: tianmoucv/proc/nn/__init__.py
 Comment: 
 
-Filename: tianmoucv/rdp_usb/compile_pybind.sh
+Filename: tianmoucv/proc/nn/spy_modules.py
 Comment: 
 
-Filename: tianmoucv/rdp_usb/rod_decoder_py.cpp
+Filename: tianmoucv/proc/nn/unet_modules.py
 Comment: 
 
-Filename: tianmoucv/rdp_usb/try_pcie2usb_conv.py
+Filename: tianmoucv/proc/nn/utils.py
 Comment: 
 
-Filename: tianmoucv/rdp_usb/try_usb_data.py
+Filename: tianmoucv/proc/opticalflow/__init__.py
+Comment: 
+
+Filename: tianmoucv/proc/opticalflow/basic.py
+Comment: 
+
+Filename: tianmoucv/proc/opticalflow/estimator.py
+Comment: 
+
+Filename: tianmoucv/proc/opticalflow/spy_net.py
+Comment: 
+
+Filename: tianmoucv/proc/reconstruct/__init__.py
 Comment: 
 
-Filename: tianmoucv/reconstructor/__init__.py
+Filename: tianmoucv/proc/reconstruct/basic.py
 Comment: 
 
-Filename: tianmoucv/reconstructor/integration.py
+Filename: tianmoucv/proc/reconstruct/integration.py
 Comment: 
 
-Filename: tianmoucv/reconstructor/modules.py
+Filename: tianmoucv/proc/reconstruct/tiny_unet.py
 Comment: 
 
-Filename: tianmoucv/reconstructor/weight/__init__.py
+Filename: tianmoucv/proc/tracking/__init__.py
 Comment: 
 
-Filename: tianmoucv/reconstructor/weight/direct_0109_with_HDR_GTver_best.ckpt
+Filename: tianmoucv/proc/tracking/feature_tracker.py
+Comment: 
+
+Filename: tianmoucv/rdp_usb/CMakeLists.txt
+Comment: 
+
+Filename: tianmoucv/rdp_usb/ReadMe.md
+Comment: 
+
+Filename: tianmoucv/rdp_usb/__init__.py
+Comment: 
+
+Filename: tianmoucv/rdp_usb/compile_pybind.bat
+Comment: 
+
+Filename: tianmoucv/rdp_usb/compile_pybind.sh
+Comment: 
+
+Filename: tianmoucv/rdp_usb/rod_decoder_py.cpp
+Comment: 
+
+Filename: tianmoucv/rdp_usb/try_pcie2usb_conv.py
+Comment: 
+
+Filename: tianmoucv/rdp_usb/try_usb_data.py
 Comment: 
 
-Filename: tianmoucv-0.2.2.2.dist-info/LICENSE
+Filename: tianmoucv-0.3.0.dist-info/LICENSE
 Comment: 
 
-Filename: tianmoucv-0.2.2.2.dist-info/METADATA
+Filename: tianmoucv-0.3.0.dist-info/METADATA
 Comment: 
 
-Filename: tianmoucv-0.2.2.2.dist-info/WHEEL
+Filename: tianmoucv-0.3.0.dist-info/WHEEL
 Comment: 
 
-Filename: tianmoucv-0.2.2.2.dist-info/top_level.txt
+Filename: tianmoucv-0.3.0.dist-info/top_level.txt
 Comment: 
 
-Filename: tianmoucv-0.2.2.2.dist-info/RECORD
+Filename: tianmoucv-0.3.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## tianmoucv/__init__.py

```diff
@@ -5,11 +5,12 @@
 import math
 import torch
 import os
 import sys
 
 # __init__.py
 __all__ = ['random', 'cv2', 'math', 'torch','os','sys']
-__author__ = 'Y. Lin, T. Wang'
+__author__ = 'Y. Lin'
+__contributor__ = 'T. Wang, Y. Chen'
 __authorEmail__ = '532109881@qq.com'
 
-print('import TianmouCV 0.2.2.2, via',__author__,' pre release version')
+print('TianMouCV™ 0.3.0, via',__author__,', update some nn-based function')
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## tianmoucv/data/tianmoucData.py

```diff
@@ -1,11 +1,11 @@
 import numpy as np
-import cv2,sys,subprocess
+import cv2,sys
 import torch
-import math,time
+import math,time,subprocess
 import torch.nn.functional as F
 import os
 flag = True
 try:
     from tianmoucv.rdp_usb import rod_decoder_py as rdc
 except:
     print("WARNING: no decoder found, try to compile under ./rod_decoder_py")
@@ -14,35 +14,57 @@
     aim_path = os.path.join(parent_folder_path,'rdp_usb')
     os.chdir(aim_path)
     current_path = os.getcwd()
     print("Current Path:", current_path)
     subprocess.run(['sh', './compile_pybind.sh'])
     from tianmoucv.rdp_usb import rod_decoder_py as rdc
     print('compile decoder successfully')
-
-
+    
 #用于重建
-from tianmoucv.isp import laplacian_blending
+from tianmoucv.proc.reconstruct import laplacian_blending
 from tianmoucv.isp import default_rgb_isp,fourdirection2xy
 from .tianmoucData_basic import TianmoucDataReader_basic
 
 class TianmoucDataReader(TianmoucDataReader_basic):
     '''
-     继承datareader，一次性读多帧
-        - N:一次性读取N帧COP成为一个片段
-        - path: string或者string的列表，会自动扫描其下所有的tmdat sample
-        - showList:是否打印信息
-        - MAXLEN:每个sample的最大长度，防止超长sample干扰训练
-        - matchkey:是否匹配某个sample name
-        - cachePath:缓存目录，None则每次重新构建数据集
-        - ifcache:是否存下所有数据的地址，方便大规模数据集下次读取
-        - speedUpRate:数据稀疏采样
-                *这部分处理不会被存储
-        输出数据是F0,F1,...,FN，F0_HDR,F1_HDR,...,FN_HDR，以及25*N*speedUpRate 帧ROD 连续
-        存储在一个字典里，上述名称为key
+    - **TianmoucDataReader(0.3.3)**
+        - ## [输入]
+        - 输入dataPath：该路径下应当包含1个或多个子目录，每个子目录对应1段Tianmouc视频。
+            - 支持string格式(仅输入1个地址)或list格式(输入1个或多个地址)。
+               - 这个地址可以是一个tmdat sample的绝对路径，也可以是数据集的路径
+               - 如果是数据集路径(path或者path的任意多层子文件夹内有多个tmdat),可以用matchkey读取特定sample，也可以合并读取
+            - 对于单目数据，每个sample下应包含rod和cone两个目录，多目数据额外还有目录rod_N和cone_N，N为相机编号N>=1
+            - 双目数据补充：20240201测试结果，在实验过程中重启GUI不会导致两个相机标签交换
+                - 只要不插拔并交换接线，整个数据集中相机的idx将保持不变
+        - 输入N：返回的dataset中包含多个sample，每个sample包含(N+1)帧COP，以及中间的所有AOP帧。
+            - 默认N=1，在757fps模式下sample中有F0，F1两帧COP，以及中间的(25+1)帧AOP，最后一帧AOP与下一个sample第1帧AOP相同，可以跳过。
+        - 输入matchkey：在dataPath所有路径下的子目录名称中匹配对应的，否则会输出所有数据。
+            - 若输入超过1个路径，建议不同路径下不要出现同名子目录，否则可能出现bug。
+        - 输入camera_idx：默认为0，表示识别单目输入，若为双目数据，则camera_idx=0,1分别录取双目数据。
+        - 原先版本中的输入参数MAXLEN强制默认设为-1，即始终为读取全部数据。
+        - ## [输出]
+        - 输出dataset调用方式类似于列表，通过sample = dataset[index]逐一获取数据。
+        - sample为字典类型，包含如下key
+            - COP帧依次记录为F0，F1，F2...F(N)
+                - 'F0'默认使用ISP算法调色
+                - 'F0_without_isp'不加额外处理，若加红外滤光片应使用这个数据
+                - 'F0_HDR'为简易融合算法处理结果，由同步的SD和RGB合成高动态图
+            - AOP帧
+                - 'rawDiff'为AOP像素原始输出(160×160，带空洞)
+                - 'tsdiff_160x320'为rawDiff进行插值去空洞后上采样的图像(160×320)
+                - 'tsdiff'为tsdiff_160x320进一步插值得到的与COP同分辨率的图像(320×640)
+                - 上述三个对应的key_value均为张量格式，torch.Size([3, X, height, width])
+                    - 第0个维度为3，分别依次对应TD，SD1，SD2
+                    - 第1个维度对应AOP帧数目，在757fps模式下X=N×25+1
+                    - 第2，3个维度对应AOP帧的分辨率
+            - 'sysTimeStamp'为系统初始时间，用于在多目相机情况下进行时间对齐。
+                - 两相机之间初始时间差为sysTimeStamp1-sysTimeStamp2，单位为秒
+                - COP对齐时若Δt>33ms/2，建议让相机1的第K+Δt/33ms帧COP与相机2的第K帧COP对齐，这样时间差更小。
+            - 'labels'用于标注HDR，HS，Blur，Noisy等4种极端情况分类，暂未实装。
+            - 'meta'包含了该段目录的一些元数据，如文件存储目录，时间戳等等，需要详细数据分析时使用
     '''
     def __init__(self,path,
                  N=1,
                  camera_idx= 0,
                  showList=True,
                  MAXLEN=-1,
                  matchkey=None,
```

## tianmoucv/data/tianmoucData_basic.py

```diff
@@ -1,31 +1,32 @@
 import numpy as np
 import os
-import cv2,sys,subprocess
+import cv2,sys
 import torch
-import math,time
+import math,time,subprocess
 import torch.nn.functional as F
 
 try:
     from tianmoucv.rdp_usb import rod_decoder_py as rdc
 except:
+    import subprocess
     print("WARNING: no decoder found, try to compile under ./rod_decoder_py")
     current_file_path = os.path.abspath(__file__)
     parent_folder_path = os.path.dirname(os.path.dirname(current_file_path))
     aim_path = os.path.join(parent_folder_path,'rdp_usb')
     os.chdir(aim_path)
     current_path = os.getcwd()
     print("Current Path:", current_path)
     subprocess.run(['sh', './compile_pybind.sh'])
     from tianmoucv.rdp_usb import rod_decoder_py as rdc
     print('compile decoder successfully')
 
 #用于重建
 #用于rgb的ISP
-from tianmoucv.isp import laplacian_blending
+from tianmoucv.proc.reconstruct import laplacian_blending
 from tianmoucv.isp import default_rgb_isp,fourdirection2xy,ACESToneMapping
 
 from ctypes import *
 
 flag = True
 
 class TianmoucDataReader_basic():
@@ -376,15 +377,15 @@
     def packRead(self,idx,key,ifSync =True, needPreProcess = True):
         '''
         use the decoder and isp preprocess to generate a paired (RGB,n*TSD) sample dict:
         
             sample['tsdiff_160x320'] = RAW TSD data ajusted to coorect space(with hollow)
             sample['tsdiff'] = TSD data upsample to 320*640
             sample['F0_without_isp'] = only demosaced frame data, 3*320*640, t=t_0
-            sample['F1_without_isp'] = only demosaced frame data, 3*320*640, t=t_0
+            sample['F1_without_isp'] = only demosaced frame data, 3*320*640, t=t_0+33ms
             sample['F0_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0
             sample['F1_HDR']: RGB+SD Blended HDR frame data, 3*320*640, t=t_0+33ms
             sample['F0']: preprocessed frame data, 3*320*640, t=t_0
             sample['F1']: preprocessed frame data, 3*320*640, t=t_0+33ms
             sample['rawDiff']: raw TSD data, N*3*160*160, from t=t_0 to t=t+33ms
             sample['meta']: path infomation and and timestamps for each data
             sample['labels']: list of labels, if you have one
```

## Comparing `tianmoucv/reconstructor/integration.py` & `tianmoucv/proc/reconstruct/tiny_unet.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,123 +1,70 @@
 import numpy as np
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import os
 import time
-from ..isp import fourdirection2xy,poisson_blend,upsampleTSD
-from .modules import UNetRecon
 
+from .basic import poisson_blend
 
-def grayReconstructor(tsdiff,F0,F1,t,TDnoise=0,threshGate=4/255):
-    '''
-    AOP+COP合成灰度
-    
-    1. 校正TD的正向和负向差分的不一致性
-    
-    2. 计算AOP到COP的线性缩放系数
-    
-    3. SD使用泊松blending合成灰度
-    
-    4. 双向TD积累+SD灰度合成最终结果
-    
-    parameter:
-        :param F0: [h,w,3],torch.Tensor
-        :param F0: [h,w,3],torch.Tensor
-        :param tsdiff: [3,T,h,w],torch.Tensor, 默认decoded结果的堆积
-        :param TDnoise: 噪声矩阵 [h,w], torch.Tensor
-        :param threshGate=4/255: 积累时的噪声阈值
-        :param t: int
-
-    '''
-    gray0 = torch.mean(F0,dim=-1)
-    gray1 = torch.mean(F1,dim=-1)
-    TD_COP = gray1-gray0
-    
-    #adjust TD bias for tianmouc
-    TD = tsdiff[0,:,...]     
-    TD[abs(TD)<threshGate]=0
-    
-    possum  = torch.sum(TD[TD>0])
-    negsum  = torch.sum(abs(TD[TD<0]))
-    bias = (negsum-possum)/TD[TD>0].view(1,-1).shape[1]
-    TD[TD>0] += bias
-    
-    TD = tsdiff[0,...] - TDnoise
-
-    AOPDiff = torch.sum(TD[1:,...],dim=0)
-    AOPDiff = F.interpolate(AOPDiff.unsqueeze(0).unsqueeze(0), size=TD_COP.shape, mode='nearest').squeeze(0).squeeze(0)
-    AOP_COP_scale_neg = torch.sum(TD_COP[TD_COP<0])/torch.sum(AOPDiff[AOPDiff<0]) 
-    AOP_COP_scale_pos = torch.sum(TD_COP[TD_COP>0])/torch.sum(AOPDiff[AOPDiff>0]) 
-
-    TD[TD<0] *= AOP_COP_scale_neg 
-    TD[TD>0] *= AOP_COP_scale_pos 
-    forward_TD =  torch.sum(TD[1:t+1,...],dim=0)
-    backward_TD =  torch.sum(TD[t+1:,...],dim=0)
-
-    '''
-    SDt = tsdiff[1:,t,...].permute(1,2,0) * (AOP_COP_scale_neg+AOP_COP_scale_pos)/2
-
-    Ix,Iy = fourdirection2xy(SDt)
-    gray = -poisson_blend(Ix,Iy,iteration=20)
-    gray = F.interpolate(gray.unsqueeze(0).unsqueeze(0), 
-                         size=(320,640), mode='bilinear').squeeze(0).squeeze(0)
-    '''
-    forward_TD  = F.interpolate(forward_TD.unsqueeze(0).unsqueeze(0), size=(320,640), mode='bilinear').squeeze(0).squeeze(0)
-    backward_TD = F.interpolate(backward_TD.unsqueeze(0).unsqueeze(0), size=(320,640), mode='bilinear').squeeze(0).squeeze(0)
-    
-    hdr = (gray0+forward_TD + gray1 - backward_TD)/2
-    
-    return hdr
-
+from tianmoucv.tools import check_url_or_local_path,download_file
+from tianmoucv.proc.nn.unet_modules import UNetRecon
+from tianmoucv.isp import fourdirection2xy,upsampleTSD
+from tianmoucv.proc.nn.utils import tdiff_split
 
 class Reconstrutor_NN(nn.Module):
     '''
     重建网络
-    权重链接:https://drive.google.com/file/d/1eWF5mW7ccSjUY93gM7bGxgwGl5z1IdlM/view?usp=share_link
+    权重链接:https://cloud.tsinghua.edu.cn/f/2baddb35cc034d31956e/?dl=1
+    old:https://cloud.tsinghua.edu.cn/f/9d4adcfa7f0245959747/?dl=1
     '''
-
-    def __init__(self,ckpt_path = None):
+    def __init__(self,ckpt_path =None,_optim=True):
         super(Reconstrutor_NN, self).__init__()
         current_dir=os.path.dirname(__file__)
+        
         if ckpt_path is None:
-            #print('use shared weight:','https://drive.google.com/file/d/1eWF5mW7ccSjUY93gM7bGxgwGl5z1IdlM/view?usp=share_link')
-            ckpt_path = os.path.join(current_dir,'weight/direct_0109_with_HDR_GTver_best.ckpt')
+            ckpt_path = 'https://cloud.tsinghua.edu.cn/f/2baddb35cc034d31956e/?dl=1'
         self.reconNet =  UNetRecon(7, 3)
-        try:
-            dict_re = torch.load(ckpt_path, map_location=torch.device('cpu'))['state_dict_ReconModel']
-            dict_reconNet = dict([])
-            for key in dict_re:
-                new_key_list = key.split('.')[1:]
-                new_key = ''
-                for e in new_key_list:
-                    new_key += e + '.'
-                new_key = new_key[:-1]
-                if 'reconNet' in key:
-                    dict_reconNet[new_key] = dict_re[key]
-            self.reconNet.load_state_dict(dict_reconNet,strict=True)
-            self.easyrecon = True
-        except:
-            self.easyrecon = False
-            self.reconNet = torch.jit.load(ckpt_path, map_location=torch.device('cpu')) 
+        status = check_url_or_local_path(ckpt_path)
+        print('loading..:',ckpt_path)
+        if status == 1:
+            default_file_name = 'tinyunet_best.ckpt'
+            if not os.path.exists(default_file_name):
+                ckpt_path = download_file(url=ckpt_path,file_name=default_file_name)
+            else:
+                ckpt_path = default_file_name
+            print('load finished')
+            
+        dict_re = torch.load(ckpt_path, map_location=torch.device('cpu'))['state_dict_ReconModel']
+        dict_reconNet = dict([])
+        for key in dict_re:
+            new_key_list = key.split('.')[1:]
+            new_key = ''
+            for e in new_key_list:
+                new_key += e + '.'
+            new_key = new_key[:-1]
+            if 'reconNet' in key:
+                dict_reconNet[new_key] = dict_re[key]
+        self.reconNet.load_state_dict(dict_reconNet,strict=True)
 
         self.eval()
         for param in self.reconNet.parameters():
             param.requires_grad = False
         main_version = int(torch.__version__[0])
-        if main_version==2:
+        if main_version==2 and _optim:
             print('compiling model for pytorch version>= 2.0.0')
             self.reconNet = torch.compile(self.reconNet)
             print('compiled!')
 
     def __call__(self, F0, tsdiff, t):
-        if self.easyrecon:
-            return self.forward_batch(F0,tsdiff).float()
+        if t == -1:
+            return self.forward_batch_direct(F0,tsdiff).float()
         else:
-            return self.complex_forward_batch(F0,tsdiff).float()
+            return self.forward_single_t(F0, tsdiff, t).float()
 
     @torch.no_grad() 
     def forward_single_t(self, F0, tsdiff, t):
         '''
           recontruct a frame
           
           @tsdiff: [c,n,w,h], -1~1,torch
@@ -137,22 +84,22 @@
             
         F0 = F0.unsqueeze(0).to(self.device)
         tsdiff = tsdiff.unsqueeze(0).to(self.device)
             
         SD1 = tsdiff[:,1:,t,...]
         TD_0_t = torch.sum(tsdiff[:,0:1,1:t,...],dim=2)
         
-        print(TD_0_t.shape,SD1.shape)
+        TD_0_t = tdiff_split(TD_0_t,cdim=1)#splie pos and neg
 
         I_1_rec = self.reconNet(torch.cat([F0,TD_0_t,SD1],dim=1))#3+1
 
         return I_1_rec 
 
     @torch.no_grad() 
-    def forward_batch(self, F0, tsdiff):
+    def forward_batch_direct(self, F0, tsdiff):
         '''
             recontruct a batch
             
             @ tsdiff: [c,n,w,h], -1~1,torch
             
             @ F0:   [w,h,c],torch
         '''
@@ -165,31 +112,38 @@
             tsdiff = F.interpolate(tsdiff, size=(h,w), mode='bilinear')
 
         F0 = F0.unsqueeze(0).to(self.device)
         tsdiff = tsdiff.unsqueeze(0).to(self.device)#[b,c,n,w,h]
             
         FO_b = torch.stack([F0[0,...]]*n2,dim=0)
         SD1_b = tsdiff[0,1:,:,...].permute(1,0,2,3)
-        #TD_0_t_b = torch.zeros([n2,1,h,w]).to(self.device)
-        #for n in range(1,n2):
-        #    TD_0_t_b[n,...] = torch.sum(tsdiff[:,0:1,1:n,...],dim=2)
-            
-                
+
         TD_0_t_b = torch.zeros([n2,2,h,w]).to(self.device)
         for n in range(1,n2):
-            td_ = tsdiff[:,0:1,1:n+1,...]
-            td_pos = td_.clone()
-            td_pos[td_pos<0] = 0
-            td_pos = torch.sum(td_pos,dim=2)
-            td_neg = td_.clone()
-            td_neg[td_neg>0] = 0
-            td_neg = torch.sum(td_neg,dim=2)
-            td = torch.cat([td_pos,td_neg],dim=1)
+            td_ = torch.sum(tsdiff[:,0:1,1:n+1,...],dim=2)
+            td = tdiff_split(td_,cdim=1)
             TD_0_t_b[n:n+1,...] = td
         
         stime = time.time()
         inputTensor = torch.cat([FO_b,TD_0_t_b,SD1_b],dim=1)
         I_1_rec = self.reconNet(inputTensor)#3+1
         etime = time.time()
         frameTime = (etime-stime)/n2
-        print(1/frameTime/n2,'batch`ps',1/frameTime, 'fps')
+        print(1/frameTime/n2,'batch`ps',1/frameTime, 'fps in average')
+        return I_1_rec 
+
+    @torch.no_grad() 
+    def forward_batch(self, F0, TFlow_0_1, SD0, SD1):
+        '''
+            recontruct a batch
+            
+            @ tsdiff: [c,n,w,h], -1~1,torch
+            
+            @ F0:   [w,h,c],torch
+        '''
+        self.device = self.reconNet.up5.conv2.weight.device
+        stime = time.time()
+        I_1_rec = self.reconNet(torch.cat([F0,TFlow_0_1,SD1],dim=1))#3+1
+        etime = time.time()
+        frameTime = (etime-stime)/n2
+        print(1/frameTime/n2,'batch`ps',1/frameTime, 'fps in average')
         return I_1_rec
```

## Comparing `tianmoucv-0.2.2.2.dist-info/LICENSE` & `tianmoucv-0.3.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `tianmoucv-0.2.2.2.dist-info/METADATA` & `tianmoucv-0.3.0.dist-info/METADATA`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: tianmoucv
-Version: 0.2.2.2
+Version: 0.3.0
 Summary: Algorithms library for Tianmouc sensor
 Home-page: https://github.com/Tianmouc/tianmoucv
 Author: Yihan Lin,Taoyi Wang
 Author-email: 532109881@qq.com
 Keywords: tianmoucv
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: License :: OSI Approved :: MIT License
@@ -20,48 +20,74 @@
 Requires-Dist: tensorboard >=2.4.1
 Requires-Dist: pandas >=1.1.4
 Requires-Dist: seaborn >=0.11.0
 Requires-Dist: pybind11
 Requires-Dist: ipython
 Requires-Dist: thop >=0.1.1
 
+![PyPI - Version](https://img.shields.io/pypi/v/tianmoucv) ![PyPI - Wheel](https://img.shields.io/pypi/wheel/tianmoucv) ![PyPI - License](https://img.shields.io/pypi/l/tianmoucv) ![PyPI - Downloads](https://img.shields.io/pypi/dm/tianmoucv) 
 
 # TianMouCV-preview version
 
-**The official version will be available at [tianmoucv/tianmocv](https://github.com/Tianmouc/tianmoucv)**
+![usbmodule](/resources/usb_module.jpg)
 
-The python tool for complementary vision sensor Tianmouc.
+**The official version will be available at [tianmoucv/tianmocv](https://github.com/Tianmouc/tianmoucv)**
 
-More details of the project can be found in our main page [doc](http://www.tianmouc.cn:38325)
+This is the Python tool for the first complementary vision sensor (CVS), TianMouC.
 
+More details about the project can be found on our project page. [doc](http://www.tianmouc.cn:38325)
 
 ## Installation
 
-(1) from PyPI(not ready)
+(0) Prepare pytorch environment
+
+**Python version should be larger than 3.8 and less than 3.12, recommend 3.10**
+
+```bash
+conda create -n [YOUR ENV NAME] --python=3.10
+conda activate [YOUR ENV NAME]
+conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
+```
+
+(1) from PyPI
 
 ```bash
 pip install tianmoucv
 ```
 
 (2) Install from source codes (using pip):
 
-**Python version should be larger than 3.8 and less than 3.12, recommand 3.10**
-
 ```bash
-conda create -n [YOUR ENV NAME] --python=3.10
-conda activate [YOUR ENV NAME]
-conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
 git clone git@github.com:Tianmouc/Tianmoucv_preview.git
 cd Tianmoucv_preview
 sh install.sh
 ```
 
-## Usage
+## Data
+
+You can download a TianMouC data clip in [THU-sharelink](https://cloud.tsinghua.edu.cn/f/dc0d394efcb44af3b9b3/?dl=1), and refer to tianmoucv/exmaple/data/test_data_read.ipynb for a trial
+
+a standard TianMouC dataset structure:
+
+```
+├── dataset
+│   ├── matchkey
+│   │   ├── cone
+│   │       ├── info.txt
+│   │       ├── xxx.tmdat
+│   │   ├── rod
+│   │       ├── info.txt
+│   │       ├── xxx.tmdat
+```
+
+where matchkey is the sample name used for the TianMouC data reader 
+
+## Examples
 
-For some of the fuction we've provided the example in tianmoucv/exmaple
+For some of the algorithms we've provided the example in tianmoucv/example
 
 Including:
 
 (1) calculating optical flow
 
 (2) reconstruct gray/hdr images
 
@@ -69,15 +95,15 @@
 
 (4) camera calibration
 
 (5) data reeader
 
 ...
 
-These sample can be directly run on jupyter notebook
+These samples can be directly run on jupyter notebook
 
 ```bash
-conda activate [your envirobnment]
+conda activate [your environment]
 pip install jupyter notebook
 jupyter notebook
 ```
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

